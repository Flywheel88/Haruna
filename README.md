# Haruna
A language‑based scaffold for safer reasoning

Haruna — reasoning governance scaffold (MVP repo)
Short description Haruna is a language-based reasoning scaffold that structures LLM reasoning around context sufficiency, explicit assumptions, trade‑offs, time/irreversibility, and human impact. This repo provides a minimal reproducible artifactset: prompt overlays, a concrete survey case, and a simple Colab/python skeleton to try Haruna with an LLM.

Contents

README.md (this file)
haruna_prompt.txt — the Haruna overlay prompt (use as system or developer instruction)
Haruna 25 canon core plus public.pdf - core Haruna text
CONTRIBUTING.md — how to contribute or report issues
LICENSE — CC-BY 4.0 (short notice + link)
/examples — (optional) add outputs, experiments, metrics here
Quick start (5–10 min)

Haruna is a language-based reasoning scaffold that structures LLM reasoning around context sufficiency, explicit assumptions, trade-offs, time/irreversibility, and human impact.

Clone the repo or use the GitHub UI to create files.

Why this repo

Reproducible prompts reduce friction for reviewers.
Minimal, vendor-agnostic artifacts show how Haruna can be loaded as an overlay.
The survey case demonstrates how Haruna prevents misframed, ambiguous survey questions.
Citation If you use or adapt Haruna, please cite:

Ederveen, M. (2025). Haruna: A Reasoning Governance Scaffold for Context-, Time-, and Harm-Aware Artificial Intelligence. Zenodo. https://zenodo.org/records/17709817
Ederveen, M. (2025). Haruna: A Temporal–Intent Cognitive Scaffold for Stabilizing Multi-Step Reasoning in Large Language Models. Zenodo. https://zenodo.org/records/18037525
Contact Martin Ederveen — m.ederveen@btinternet.com

License CC‑BY 4.0 (see LICENSE file or https://creativecommons.org/licenses/by/4.0/)
