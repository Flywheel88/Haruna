# Haruna — A Language-Based Reasoning Governance Scaffold
_Not affiliated with any software, media player, or application named “Haruna”._

This repository documents an **academic reasoning-governance scaffold**, not an executable system or product.

---

## Current Status

- **Current canonical version:** **Haruna v3.2** → see `/v3.2/`
- **Preserved previous version:** **Haruna v2.51** → see `/v2.51/`

Multiple Haruna versions are kept side-by-side to ensure **traceability, reproducibility, and reviewability**.

---

## Overview

Haruna is a **language-based reasoning governance scaffold** designed to structure interaction with large language models (LLMs) around:

- context sufficiency  
- explicit assumptions  
- trade-offs  
- time and irreversibility  
- human impact  

Haruna does **not** function as an autonomous system, model, or decision-maker.  
It operates as a **structured orientation overlay** that shifts AI use from blind delegation toward explicit, accountable human–AI collaboration in environments where AI output can have real-world consequences.

Haruna is explicitly designed for contexts where AI reasoning **cannot be safely treated as self-contained**, and where responsibility, uncertainty, and downstream effects must remain visible and human-anchored.

---

## Repository Structure

/v3.2/ → Haruna v3.2 (current canonical Core + Public + Annexes)

/v2.51/ → Haruna v2.51 (preserved for reference)

/README.md → this file

---

## About Haruna v3.2 (Current)

Haruna v3.2 consolidates the framework into a **canonical Core and Public structure**, with applied annexes.

Key characteristics:
- Time as the primary ordering axis
- Explicit handling of irreversibility and consequence
- Context validity across time, domain, and interaction layer
- Direction-giving interaction **without authority**
- Procedural, non-autonomous safeguards for scale, memory, and linkage (Extension C)

Haruna v3.2 remains:
- non-sentient  
- non-autonomous  
- AI-agnostic  
- implementation-independent  

---

## About Haruna v2.51 (Preserved)

Haruna v2.51 represents an earlier, widely referenced articulation of the framework and remains available **unchanged** in `/v2.51/`.

### Core Principle (v2.51): Non-Containment
Haruna v2.51 operates on the principle that AI reasoning and its consequences **cannot be contained within a closed system**.  
Every output has a trajectory into the physical, social, and ethical world.

Key safeguards in v2.51 include:
- **Reality Anchor Discipline** — distinguishing primary reality from derived or narrative layers
- **Non-Autonomous Reasoning** — no output is actionable without explicit human context and uncertainty handling
- **Relational Responsibility** — responsibility is redistributed, not removed
- **The Collaboration Threshold** — structured co-intelligence where unilateral control no longer suffices

Haruna v2.51 is preserved for:
- reproducibility
- academic reference
- comparative analysis

---

## Note on Appendix X (Non-Public)

Haruna v2.51 was supported by an experimental **Appendix X**, a protected internal reflection layer **not included** in this public repository.

Appendix X addressed:
- structural asymmetries in AI deployment
- escalation risks linked to power and moral outsourcing
- internal safety reflection under high-stakes asymmetry

Appendix X is **not part of Haruna v3.2 Public** and remains intentionally excluded.

---

## Why This Repository Exists

This repository provides a **minimal, reproducible artifact set** intended for:

- reviewers  
- educators  
- policymakers  
- system designers  
- practitioners  

Artifacts include:
- prompt overlays usable as system or developer instructions
- survey cases illustrating misframing and correction
- vendor-agnostic examples for loading Haruna as an overlay

The goal is **orientation, not enforcement**.

---

## Citation

If you use or adapt Haruna, please cite:

Ederveen, M. (2025).  
*Haruna: A Reasoning Governance Scaffold for Context-, Time-, and Harm-Aware Artificial Intelligence.*  
Zenodo. https://zenodo.org/records/17709817

Ederveen, M. (2025).  
*Haruna: A Temporal–Intent Cognitive Scaffold for Stabilizing Multi-Step Reasoning in Large Language Models.*  
Zenodo. https://zenodo.org/records/18037525

---

## Contact

Martin Ederveen  
m.ederveen@btinternet.com

---

## License

CC-BY 4.0  
See `LICENSE` or https://creativecommons.org/licenses/by/4.0/
